{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPv8NnH75z0cUImcimB4OoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namesarnav/SimMIM/blob/main/ViT_MIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masked Image Modeling using ViT-B on a CIFAR-100 dataset"
      ],
      "metadata": {
        "id": "ccmuLCSBKrD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8eWJdFs0RgNo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 2048\n",
        "EPOCHS = 15\n",
        "LEARNING_RATE = 3e-4\n",
        "WEIGHT_DECAY = 0.01\n",
        "IMAGE_SIZE = 32  # CIFAR images are 32x32\n",
        "PATCH_SIZE = 4  # Size of patches for ViT\n",
        "NUM_CLASSES = 100  # CIFAR-100 has 100 classes\n",
        "MASK_RATIO = 0.75  # Portion of patches to mask\n",
        "EMBED_DIM = 384  # Embedding dimension\n",
        "DEPTH = 6  # Number of transformer layers\n",
        "NUM_HEADS = 6  # Number of attention heads\n",
        "MLP_RATIO = 4.0  # Ratio for MLP hidden dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_JR71sBRieq",
        "outputId": "59898810-a8fa-4035-b580-0df4ba7c35fd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer components\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = Attention(\n",
        "            dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = MLP(dim=dim, hidden_dim=mlp_hidden_dim, dropout=drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yTkTeiHfRmOE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked Image Modeling ViT\n",
        "class MaskedVisionTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size=IMAGE_SIZE,\n",
        "        patch_size=PATCH_SIZE,\n",
        "        in_chans=3,\n",
        "        embed_dim=EMBED_DIM,\n",
        "        depth=DEPTH,\n",
        "        num_heads=NUM_HEADS,\n",
        "        mlp_ratio=MLP_RATIO,\n",
        "        qkv_bias=True,\n",
        "        drop_rate=0.1,\n",
        "        attn_drop_rate=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.in_chans = in_chans\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Number of patches\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embed = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size),\n",
        "            nn.Linear(patch_size * patch_size * in_chans, embed_dim),\n",
        "        )\n",
        "\n",
        "        # CLS token and positional embedding\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, embed_dim))\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(\n",
        "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate\n",
        "            )\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        # Norm layer\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize weights\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Simplified decoder for SimMIM\n",
        "        # In SimMIM, the decoder is intentionally kept very lightweight - just a linear projection\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, patch_size * patch_size * in_chans),\n",
        "            Rearrange('b (h w) (p1 p2 c) -> b c (h p1) (w p2)',\n",
        "                      h=img_size//patch_size, w=img_size//patch_size,\n",
        "                      p1=patch_size, p2=patch_size)\n",
        "        )\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    def random_masking(self, x, mask_ratio):\n",
        "        \"\"\"\n",
        "        Perform random masking following SimMIM approach - independent random masking.\n",
        "\n",
        "        Args:\n",
        "            x: [N, L, D], sequence\n",
        "            mask_ratio: percentage of tokens to be masked\n",
        "\n",
        "        Returns:\n",
        "            x_unchanged: [N, L, D], the original sequence (not actually masked)\n",
        "            mask: [N, L], mask -> 0 is keep, 1 is mask (matches SimMIM notation)\n",
        "            ids_restore: None (not needed for SimMIM approach)\n",
        "        \"\"\"\n",
        "        N, L, D = x.shape  # batch, length, dim\n",
        "\n",
        "        # Generate random mask - following SimMIM's approach of independent random masking\n",
        "        # In SimMIM, mask=1 means the token is masked, mask=0 means it's kept\n",
        "        mask = torch.bernoulli(torch.ones(N, L, device=x.device) * mask_ratio)\n",
        "\n",
        "        # In SimMIM, we don't actually need to mask the sequence for the encoder\n",
        "        # The entire sequence is processed, and the loss is only applied on masked tokens\n",
        "\n",
        "        return x, mask, None\n",
        "\n",
        "    def forward_encoder(self, img, mask_ratio):\n",
        "        # Convert image to patches\n",
        "        patches = self.patch_embed(img)  # [B, num_patches, embed_dim]\n",
        "\n",
        "        # Add position embeddings (exclude CLS token position at this point)\n",
        "        patches = patches + self.pos_embed[:, 1:, :]\n",
        "\n",
        "        # Apply masking strategy (following SimMIM, this doesn't actually mask inputs)\n",
        "        patches, mask, _ = self.random_masking(patches, mask_ratio)\n",
        "\n",
        "        # Append CLS token\n",
        "        cls_token = self.cls_token + self.pos_embed[:, :1, :]\n",
        "        cls_tokens = cls_token.expand(patches.shape[0], -1, -1)\n",
        "        x = torch.cat((cls_tokens, patches), dim=1)\n",
        "\n",
        "        # Apply Transformer blocks\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        # Apply norm\n",
        "        x = self.norm(x)\n",
        "\n",
        "        return x, mask\n",
        "\n",
        "    def forward_decoder(self, x):\n",
        "        \"\"\"\n",
        "        SimMIM-style lightweight decoder - just project encoded patches back to pixels\n",
        "        \"\"\"\n",
        "        # Exclude CLS token\n",
        "        x = x[:, 1:, :]\n",
        "\n",
        "        # Following SimMIM's lightweight decoder approach\n",
        "        # Just a simple linear projection from embeddings back to pixels\n",
        "        pixels = self.decoder(x)\n",
        "\n",
        "        return pixels\n",
        "\n",
        "    def forward(self, imgs, mask_ratio=MASK_RATIO):\n",
        "        # Encoding with masking strategy (SimMIM style)\n",
        "        latent, mask = self.forward_encoder(imgs, mask_ratio)\n",
        "\n",
        "        # Decoding to reconstruct original image with simplified decoder\n",
        "        pred = self.forward_decoder(latent)\n",
        "\n",
        "        return pred, mask"
      ],
      "metadata": {
        "id": "PtHBfQUwRp21"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset preparation with transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "trainset = CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# Create model\n",
        "model = MaskedVisionTransformer().to(device)\n",
        "\n",
        "# L1 Loss for Masked Image Modeling\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
      ],
      "metadata": {
        "id": "NO3EC0J1RsZN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function following SimMIM approach\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    for i, (images, _) in progress_bar:\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass with masking\n",
        "        reconstructed, mask = model(images)\n",
        "\n",
        "        # Calculate loss only on masked patches - SimMIM style\n",
        "        # In SimMIM, mask=1 means the token is masked\n",
        "        loss = compute_simmim_loss(criterion, reconstructed, images, mask)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update statistics\n",
        "        running_loss += loss.item()\n",
        "        progress_bar.set_postfix({\"Loss\": f\"{running_loss/(i+1):.4f}\"})\n",
        "\n",
        "    return running_loss / len(dataloader)\n",
        "\n",
        "# SimMIM loss computation - only on masked patches\n",
        "def compute_simmim_loss(criterion, pred, target, mask):\n",
        "    \"\"\"\n",
        "    Compute L1 loss only on masked patches as in SimMIM\n",
        "\n",
        "    Args:\n",
        "        criterion: loss function (L1Loss)\n",
        "        pred: [B, C, H, W] reconstructed images\n",
        "        target: [B, C, H, W] original images\n",
        "        mask: [B, L] binary mask (1 = masked, 0 = kept)\n",
        "\n",
        "    Returns:\n",
        "        loss: scalar\n",
        "    \"\"\"\n",
        "    # Reshape images to match mask dimensions\n",
        "    B, C, H, W = pred.shape\n",
        "    patch_size = PATCH_SIZE\n",
        "\n",
        "    # Reshape predictions and targets to patch-level\n",
        "    # [B, C, H, W] -> [B, L, C*P*P] where L is number of patches, P is patch size\n",
        "    pred = rearrange(pred, 'b c (h p1) (w p2) -> b (h w) (c p1 p2)', p1=patch_size, p2=patch_size)\n",
        "    target = rearrange(target, 'b c (h p1) (w p2) -> b (h w) (c p1 p2)', p1=patch_size, p2=patch_size)\n",
        "\n",
        "    # Apply mask: only compute loss on masked patches (where mask == 1)\n",
        "    loss = criterion(pred[mask.bool()], target[mask.bool()])\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Function to visualize original and reconstructed images with SimMIM masking\n",
        "def visualize_reconstruction(model, dataloader, device, num_images=5):\n",
        "    model.eval()\n",
        "    images, _ = next(iter(dataloader))\n",
        "    images = images[:num_images].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        reconstructed, mask = model(images)\n",
        "\n",
        "    # Convert mask for visualization\n",
        "    # In SimMIM, mask=1 means the token is masked, so we need to reshape it for display\n",
        "    mask_vis = mask.reshape(mask.shape[0], 8, 8)  # Assuming 32x32 image with 4x4 patches\n",
        "    mask_vis = mask_vis.unsqueeze(1).repeat(1, 3, 1, 1)  # [B, 3, 8, 8]\n",
        "    # Upsample mask to match image dimensions\n",
        "    mask_vis = F.interpolate(mask_vis.float(), size=(32, 32), mode='nearest')\n",
        "\n",
        "    # Convert to CPU for plotting\n",
        "    images = images.cpu()\n",
        "    reconstructed = reconstructed.cpu()\n",
        "    mask_vis = mask_vis.cpu()\n",
        "\n",
        "    # Denormalize images\n",
        "    mean = torch.tensor([0.5071, 0.4867, 0.4408]).view(1, 3, 1, 1)\n",
        "    std = torch.tensor([0.2675, 0.2565, 0.2761]).view(1, 3, 1, 1)\n",
        "\n",
        "    images = images * std + mean\n",
        "    reconstructed = reconstructed * std + mean\n",
        "\n",
        "    # Clip values to [0, 1] range\n",
        "    images = torch.clamp(images, 0, 1)\n",
        "    reconstructed = torch.clamp(reconstructed, 0, 1)\n",
        "\n",
        "    # Create masked image by combining original and reconstructed based on mask\n",
        "    masked_imgs = images.clone()\n",
        "    for i in range(num_images):\n",
        "        # Apply mask - use reconstructed image where mask=1 (masked regions)\n",
        "        mask_image = mask_vis[i]\n",
        "        masked_imgs[i] = images[i] * (1 - mask_image) + reconstructed[i] * mask_image\n",
        "\n",
        "    # Plot\n",
        "    fig, axs = plt.subplots(3, num_images, figsize=(15, 8))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Original\n",
        "        axs[0, i].imshow(images[i].permute(1, 2, 0))\n",
        "        axs[0, i].set_title(\"Original\")\n",
        "        axs[0, i].axis('off')\n",
        "\n",
        "        # Mask visualization (white = masked in SimMIM)\n",
        "        axs[1, i].imshow(mask_vis[i].permute(1, 2, 0), cmap='gray')\n",
        "        axs[1, i].set_title(\"Mask (white=masked)\")\n",
        "        axs[1, i].axis('off')\n",
        "\n",
        "        # Reconstructed\n",
        "        axs[2, i].imshow(masked_imgs[i].permute(1, 2, 0))\n",
        "        axs[2, i].set_title(\"Masked + Reconstructed\")\n",
        "        axs[2, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"simmim_reconstruction_example.png\")\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "hvQ8thr1Rxds"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, lr_scheduler, device, epochs):\n",
        "    best_loss = float('inf')\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train for one epoch\n",
        "        train_loss = train_epoch(model, trainloader, criterion, optimizer, device, epoch)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Update learning rate\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint if best model\n",
        "        if train_loss < best_loss:\n",
        "            best_loss = train_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': best_loss,\n",
        "            }, 'best_vit_mim_model.pth')\n",
        "            print(f\"Checkpoint saved (Loss: {best_loss:.4f})\")\n",
        "\n",
        "        # Visualize reconstruction every 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            visualize_reconstruction(model, testloader, device)\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Over Time')\n",
        "    plt.legend()\n",
        "    plt.savefig('training_loss.png')\n",
        "    plt.close()\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting training Vision Transformer with Masked Image Modeling on CIFAR-100...\")\n",
        "\n",
        "    # Train the model\n",
        "    losses = train_model(\n",
        "        model=model,\n",
        "        trainloader=trainloader,\n",
        "        testloader=testloader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        lr_scheduler=lr_scheduler,\n",
        "        device=device,\n",
        "        epochs=EPOCHS\n",
        "    )\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    # Load best model for final visualization\n",
        "    checkpoint = torch.load('best_vit_mim_model.pth')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Final reconstruction visualization\n",
        "    print(\"Creating final reconstruction visualization...\")\n",
        "    visualize_reconstruction(model, testloader, device, num_images=8)\n",
        "    print(\"Visualization saved as 'reconstruction_example.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD7h9XKyRU2A",
        "outputId": "a5b9e06e-87fa-42d0-d3b2-02e29256136f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training Vision Transformer with Masked Image Modeling on CIFAR-100...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.3742]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Train Loss: 0.3742\n",
            "Checkpoint saved (Loss: 0.3742)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.1901]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15, Train Loss: 0.1901\n",
            "Checkpoint saved (Loss: 0.1901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.1484]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15, Train Loss: 0.1484\n",
            "Checkpoint saved (Loss: 0.1484)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.1335]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15, Train Loss: 0.1335\n",
            "Checkpoint saved (Loss: 0.1335)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.1162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15, Train Loss: 0.1162\n",
            "Checkpoint saved (Loss: 0.1162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6/15:   0%|          | 0/25 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "            ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^ \n",
            " AssertionError :  can only test a child process\n",
            "  ^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^\n",
            "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "          ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^^ ^ ^  ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "\n",
            " AssertionError :  can only test a child process \n",
            "   ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    \n",
            "if w.is_alive():  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "        ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Epoch 6/15: 100%|██████████| 25/25 [00:18<00:00,  1.38it/s, Loss=0.1079]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15, Train Loss: 0.1079\n",
            "Checkpoint saved (Loss: 0.1079)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 7/15:   0%|          | 0/25 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^\n",
            "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            "      if w.is_alive(): \n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^ ^ ^ \n",
            " AssertionError : ^can only test a child process^\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    \n",
            "self._shutdown_workers()  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive(): \n",
            "               ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^\n",
            "^AssertionError^: ^^can only test a child process\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^ ^ ^ \n",
            "  AssertionError^: can only test a child process^^\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "\n",
            "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            "      if w.is_alive(): \n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^^ ^ ^ ^ ^ ^ ^ ^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Epoch 7/15: 100%|██████████| 25/25 [00:18<00:00,  1.39it/s, Loss=0.1020]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15, Train Loss: 0.1020\n",
            "Checkpoint saved (Loss: 0.1020)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8/15:   0%|          | 0/25 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^Exception ignored in: \n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "      self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "      if w.is_alive(): \n",
            "        ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^^ ^ ^ ^ ^ \n",
            " AssertionError^: ^can only test a child process^\n",
            "^^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^\n",
            "Exception ignored in:   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "      self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "      ^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^  \n",
            "AssertionError : ^can only test a child process^\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            " ^^ ^  ^^ ^ ^ ^^^^^^^^^^\n",
            "^^AssertionError^: ^can only test a child process^\n",
            "^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "       self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "      if w.is_alive(): \n",
            "    ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^^ ^ \n",
            " AssertionError : can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Epoch 8/15: 100%|██████████| 25/25 [00:18<00:00,  1.38it/s, Loss=0.0967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15, Train Loss: 0.0967\n",
            "Checkpoint saved (Loss: 0.0967)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15:   4%|▍         | 1/25 [00:01<00:36,  1.53s/it, Loss=0.0929]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "   Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20> \n",
            " Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^^if w.is_alive():^\n",
            "^ ^ \n",
            "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^\n",
            "    AssertionErrorif w.is_alive():: \n",
            "can only test a child process \n",
            "      Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ \n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "     ^ ^ ^ ^^ ^ ^ ^  ^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    \n",
            "if w.is_alive():AssertionError\n",
            ":  can only test a child process \n",
            "    Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ \n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^^ ^ ^ ^ ^ ^ ^ ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Epoch 9/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0914]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15, Train Loss: 0.0914\n",
            "Checkpoint saved (Loss: 0.0914)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15:   4%|▍         | 1/25 [00:01<00:36,  1.52s/it, Loss=0.0892]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "     Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20> ^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^^if w.is_alive():^\n",
            "\n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "    ^ ^  ^ ^ ^ ^ ^ ^ ^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    \n",
            "if w.is_alive():\n",
            "AssertionError:  can only test a child process \n",
            "     Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    if w.is_alive():^^\n",
            " \n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "    ^ ^ ^ ^^ ^ ^  ^ ^^ ^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^ ^ ^ ^ ^ ^ ^ ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^^: ^can only test a child process\n",
            "^^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    \n",
            "if w.is_alive():AssertionError\n",
            ":  can only test a child process \n",
            "    Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7feca9196a20>^\n",
            "^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ \n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "  ^ ^ ^ ^ ^ ^ ^ ^ ^^ ^ ^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^  ^ ^ ^^  ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Epoch 10/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0884]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15, Train Loss: 0.0884\n",
            "Checkpoint saved (Loss: 0.0884)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0861]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15, Train Loss: 0.0861\n",
            "Checkpoint saved (Loss: 0.0861)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0846]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15, Train Loss: 0.0846\n",
            "Checkpoint saved (Loss: 0.0846)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0837]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15, Train Loss: 0.0837\n",
            "Checkpoint saved (Loss: 0.0837)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0831]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15, Train Loss: 0.0831\n",
            "Checkpoint saved (Loss: 0.0831)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s, Loss=0.0828]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15, Train Loss: 0.0828\n",
            "Checkpoint saved (Loss: 0.0828)\n",
            "Training complete!\n",
            "Creating final reconstruction visualization...\n",
            "Visualization saved as 'reconstruction_example.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwQkN02pVyqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}